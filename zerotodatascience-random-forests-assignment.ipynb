{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "completed-acrobat",
   "metadata": {
    "id": "completed-acrobat"
   },
   "source": [
    "# Assignment - Decision Trees and Random Forests\n",
    "\n",
    "This assignmnt is a part of the [Zero to Data Science Bootcamp by Jovian](https://zerotodatascience.com)\n",
    "\n",
    "![](https://i.imgur.com/3sw1fY9.jpg)\n",
    "\n",
    "In this assignment, you'll train decision trees and random forests to predict the price of a house using information like its location, area, no. of rooms etc. You'll use the dataset from the [House Prices - Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques) competition on [Kaggle](https://kaggle.com). \n",
    "\n",
    "We'll follow a step-by-step process:\n",
    "\n",
    "1. Download and prepare the dataset for training\n",
    "2. Train, evaluate and interpret a decision tree\n",
    "3. Train, evaluate and interpret a random forest\n",
    "4. Tune hyperparameters to improve the model\n",
    "5. Make predictions and save the model\n",
    "\n",
    "As you go through this notebook, you will find a **???** in certain places. Your job is to replace the **???** with appropriate code or values, to ensure that the notebook runs properly end-to-end and your machine learning model is trained properly without errors. \n",
    "\n",
    "**Guidelines**\n",
    "\n",
    "1. Make sure to run all the code cells in order. Otherwise, you may get errors like `NameError` for undefined variables.\n",
    "2. Do not change variable names, delete cells, or disturb other existing code. It may cause problems during evaluation.\n",
    "3. In some cases, you may need to add some code cells or new statements before or after the line of code containing the **???**. \n",
    "4. Since you'll be using a temporary online service for code execution, save your work by running `jovian.commit` at regular intervals.\n",
    "5. Review the \"Evaluation Criteria\" for the assignment carefully and make sure your submission meets all the criteria.\n",
    "6. Questions marked **(Optional)** will not be considered for evaluation and can be skipped. They are for your learning.\n",
    "7. It's okay to ask for help & discuss ideas on the [Slack Group](https://zerotodatascience.slack.com), but please don't post full working code, to give everyone an opportunity to solve the assignment on their own.\n",
    "\n",
    "\n",
    "**Important Links**:\n",
    "\n",
    "- Make a submission here: https://jovian.ai/learn/zero-to-data-analyst-bootcamp/assignment/assignment-9-decision-trees-and-random-forests\n",
    "- Review this Jupyter notebook: https://jovian.ai/aakashns/sklearn-decision-trees-random-forests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-hormone",
   "metadata": {
    "id": "fluid-hormone"
   },
   "source": [
    "## How to Run the Code and Save Your Work\n",
    "\n",
    "**Option 1: Running using free online resources (1-click, recommended):** The easiest way to start executing the code is to click the **Run** button at the top of this page and select **Run on Binder**. This will set up a cloud-based Jupyter notebook server and allow you to modify/execute the code.\n",
    "\n",
    "\n",
    "**Option 2: Running on your computer locally:** To run the code on your computer locally, you'll need to set up [Python](https://www.python.org), download the notebook and install the required libraries. Click the **Run** button at the top of this page, select the **Run Locally** option, and follow the instructions.\n",
    "\n",
    "**Saving your work**: You can save a snapshot of the assignment to your [Jovian](https://jovian.ai) profile, so that you can access it later and continue your work. Keep saving your work by running `jovian.commit` from time to time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enhanced-volume",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8853,
     "status": "ok",
     "timestamp": 1682181801433,
     "user": {
      "displayName": "Sneha Gilada",
      "userId": "11187013067721584331"
     },
     "user_tz": -330
    },
    "id": "enhanced-volume",
    "outputId": "fd7aef1a-8fe7-466c-8e81-eb083e378811"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "saved-police",
   "metadata": {
    "executionInfo": {
     "elapsed": 1520,
     "status": "ok",
     "timestamp": 1682181807043,
     "user": {
      "displayName": "Sneha Gilada",
      "userId": "11187013067721584331"
     },
     "user_tz": -330
    },
    "id": "saved-police"
   },
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "offshore-musical",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1682181889112,
     "user": {
      "displayName": "Sneha Gilada",
      "userId": "11187013067721584331"
     },
     "user_tz": -330
    },
    "id": "offshore-musical",
    "outputId": "a59e76f9-96ee-4588-887b-d4c871ffc19a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] jovian.commit() is no longer required on Google Colab. If you ran this notebook from Jovian, \n",
      "then just save this file in Colab using Ctrl+S/Cmd+S and it will be updated on Jovian. \n",
      "Also, you can also delete this cell, it's no longer necessary.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.commit(project='zerotodatascience-random-forests-assignment', privacy='secret')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-rhythm",
   "metadata": {
    "id": "hourly-rhythm"
   },
   "source": [
    "Let's begin by installing the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continent-yacht",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36843,
     "status": "ok",
     "timestamp": 1682181933834,
     "user": {
      "displayName": "Sneha Gilada",
      "userId": "11187013067721584331"
     },
     "user_tz": -330
    },
    "id": "continent-yacht",
    "outputId": "c0bce477-2154-416b-f4dc-f7b998d162d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install opendatasets scikit-learn plotly folium --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "australian-suicide",
   "metadata": {
    "executionInfo": {
     "elapsed": 6763,
     "status": "ok",
     "timestamp": 1682183336461,
     "user": {
      "displayName": "Sneha Gilada",
      "userId": "11187013067721584331"
     },
     "user_tz": -330
    },
    "id": "australian-suicide"
   },
   "outputs": [],
   "source": [
    "!pip install pandas numpy matplotlib seaborn --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-thanksgiving",
   "metadata": {
    "id": "twelve-thanksgiving"
   },
   "source": [
    "## Download and prepare the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aggressive-taste",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1019,
     "status": "ok",
     "timestamp": 1682183392635,
     "user": {
      "displayName": "Sneha Gilada",
      "userId": "11187013067721584331"
     },
     "user_tz": -330
    },
    "id": "aggressive-taste",
    "outputId": "9d769863-71e3-424f-b3bb-ecb354cac146"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv', 'sample_submission.csv', 'data_description.txt', 'train.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "dataset_url = 'https://github.com/JovianML/opendatasets/raw/master/data/house-prices-advanced-regression-techniques.zip'\n",
    "urlretrieve(dataset_url, 'house-prices.zip')\n",
    "with ZipFile('house-prices.zip') as f:\n",
    "    f.extractall(path='house-prices')\n",
    "    \n",
    "os.listdir('house-prices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tracked-window",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 1366,
     "status": "ok",
     "timestamp": 1682183800078,
     "user": {
      "displayName": "Sneha Gilada",
      "userId": "11187013067721584331"
     },
     "user_tz": -330
    },
    "id": "tracked-window",
    "outputId": "f1d0cf3b-d091-4414-b43a-acff963b31e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f467149f-3730-4335-b5d0-795caa8f3d8d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>LowQualFinSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Functional</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>196.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>706</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>1710</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>8</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>978</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>486</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "      <td>920</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>1786</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>Wd Shng</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>216</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>540</td>\n",
       "      <td>756</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>350.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>655</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>1145</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>2198</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Gilbert</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>PConc</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>953</td>\n",
       "      <td>953</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>953</td>\n",
       "      <td>694</td>\n",
       "      <td>0</td>\n",
       "      <td>1647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>7</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NWAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>Stone</td>\n",
       "      <td>119.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>790</td>\n",
       "      <td>Rec</td>\n",
       "      <td>163</td>\n",
       "      <td>589</td>\n",
       "      <td>1542</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>2073</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2073</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>7</td>\n",
       "      <td>Min1</td>\n",
       "      <td>2</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>2</td>\n",
       "      <td>500</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>2Story</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>CemntBd</td>\n",
       "      <td>CmentBd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Stone</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>No</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>275</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0</td>\n",
       "      <td>877</td>\n",
       "      <td>1152</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1188</td>\n",
       "      <td>1152</td>\n",
       "      <td>0</td>\n",
       "      <td>2340</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>9</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>RFn</td>\n",
       "      <td>1</td>\n",
       "      <td>252</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>Hip</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Mn</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>49</td>\n",
       "      <td>Rec</td>\n",
       "      <td>1029</td>\n",
       "      <td>0</td>\n",
       "      <td>1078</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>FuseA</td>\n",
       "      <td>1078</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>5</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>1Story</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>Gable</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>830</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>290</td>\n",
       "      <td>136</td>\n",
       "      <td>1256</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>1256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>6</td>\n",
       "      <td>Typ</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>Fin</td>\n",
       "      <td>1</td>\n",
       "      <td>276</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>736</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f467149f-3730-4335-b5d0-795caa8f3d8d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f467149f-3730-4335-b5d0-795caa8f3d8d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f467149f-3730-4335-b5d0-795caa8f3d8d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig LandSlope Neighborhood Condition1  \\\n",
       "0            Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "1            Lvl    AllPub       FR2       Gtl      Veenker      Feedr   \n",
       "2            Lvl    AllPub    Inside       Gtl      CollgCr       Norm   \n",
       "3            Lvl    AllPub    Corner       Gtl      Crawfor       Norm   \n",
       "4            Lvl    AllPub       FR2       Gtl      NoRidge       Norm   \n",
       "...          ...       ...       ...       ...          ...        ...   \n",
       "1455         Lvl    AllPub    Inside       Gtl      Gilbert       Norm   \n",
       "1456         Lvl    AllPub    Inside       Gtl       NWAmes       Norm   \n",
       "1457         Lvl    AllPub    Inside       Gtl      Crawfor       Norm   \n",
       "1458         Lvl    AllPub    Inside       Gtl        NAmes       Norm   \n",
       "1459         Lvl    AllPub    Inside       Gtl      Edwards       Norm   \n",
       "\n",
       "     Condition2 BldgType HouseStyle  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          Norm     1Fam     2Story            7            5       2003   \n",
       "1          Norm     1Fam     1Story            6            8       1976   \n",
       "2          Norm     1Fam     2Story            7            5       2001   \n",
       "3          Norm     1Fam     2Story            7            5       1915   \n",
       "4          Norm     1Fam     2Story            8            5       2000   \n",
       "...         ...      ...        ...          ...          ...        ...   \n",
       "1455       Norm     1Fam     2Story            6            5       1999   \n",
       "1456       Norm     1Fam     1Story            6            6       1978   \n",
       "1457       Norm     1Fam     2Story            7            9       1941   \n",
       "1458       Norm     1Fam     1Story            5            6       1950   \n",
       "1459       Norm     1Fam     1Story            5            6       1965   \n",
       "\n",
       "      YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType  \\\n",
       "0             2003     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "1             1976     Gable  CompShg     MetalSd     MetalSd       None   \n",
       "2             2002     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "3             1970     Gable  CompShg     Wd Sdng     Wd Shng       None   \n",
       "4             2000     Gable  CompShg     VinylSd     VinylSd    BrkFace   \n",
       "...            ...       ...      ...         ...         ...        ...   \n",
       "1455          2000     Gable  CompShg     VinylSd     VinylSd       None   \n",
       "1456          1988     Gable  CompShg     Plywood     Plywood      Stone   \n",
       "1457          2006     Gable  CompShg     CemntBd     CmentBd       None   \n",
       "1458          1996       Hip  CompShg     MetalSd     MetalSd       None   \n",
       "1459          1965     Gable  CompShg     HdBoard     HdBoard       None   \n",
       "\n",
       "      MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond  \\\n",
       "0          196.0        Gd        TA      PConc       Gd       TA   \n",
       "1            0.0        TA        TA     CBlock       Gd       TA   \n",
       "2          162.0        Gd        TA      PConc       Gd       TA   \n",
       "3            0.0        TA        TA     BrkTil       TA       Gd   \n",
       "4          350.0        Gd        TA      PConc       Gd       TA   \n",
       "...          ...       ...       ...        ...      ...      ...   \n",
       "1455         0.0        TA        TA      PConc       Gd       TA   \n",
       "1456       119.0        TA        TA     CBlock       Gd       TA   \n",
       "1457         0.0        Ex        Gd      Stone       TA       Gd   \n",
       "1458         0.0        TA        TA     CBlock       TA       TA   \n",
       "1459         0.0        Gd        TA     CBlock       TA       TA   \n",
       "\n",
       "     BsmtExposure BsmtFinType1  BsmtFinSF1 BsmtFinType2  BsmtFinSF2  \\\n",
       "0              No          GLQ         706          Unf           0   \n",
       "1              Gd          ALQ         978          Unf           0   \n",
       "2              Mn          GLQ         486          Unf           0   \n",
       "3              No          ALQ         216          Unf           0   \n",
       "4              Av          GLQ         655          Unf           0   \n",
       "...           ...          ...         ...          ...         ...   \n",
       "1455           No          Unf           0          Unf           0   \n",
       "1456           No          ALQ         790          Rec         163   \n",
       "1457           No          GLQ         275          Unf           0   \n",
       "1458           Mn          GLQ          49          Rec        1029   \n",
       "1459           No          BLQ         830          LwQ         290   \n",
       "\n",
       "      BsmtUnfSF  TotalBsmtSF Heating HeatingQC CentralAir Electrical  \\\n",
       "0           150          856    GasA        Ex          Y      SBrkr   \n",
       "1           284         1262    GasA        Ex          Y      SBrkr   \n",
       "2           434          920    GasA        Ex          Y      SBrkr   \n",
       "3           540          756    GasA        Gd          Y      SBrkr   \n",
       "4           490         1145    GasA        Ex          Y      SBrkr   \n",
       "...         ...          ...     ...       ...        ...        ...   \n",
       "1455        953          953    GasA        Ex          Y      SBrkr   \n",
       "1456        589         1542    GasA        TA          Y      SBrkr   \n",
       "1457        877         1152    GasA        Ex          Y      SBrkr   \n",
       "1458          0         1078    GasA        Gd          Y      FuseA   \n",
       "1459        136         1256    GasA        Gd          Y      SBrkr   \n",
       "\n",
       "      1stFlrSF  2ndFlrSF  LowQualFinSF  GrLivArea  BsmtFullBath  BsmtHalfBath  \\\n",
       "0          856       854             0       1710             1             0   \n",
       "1         1262         0             0       1262             0             1   \n",
       "2          920       866             0       1786             1             0   \n",
       "3          961       756             0       1717             1             0   \n",
       "4         1145      1053             0       2198             1             0   \n",
       "...        ...       ...           ...        ...           ...           ...   \n",
       "1455       953       694             0       1647             0             0   \n",
       "1456      2073         0             0       2073             1             0   \n",
       "1457      1188      1152             0       2340             0             0   \n",
       "1458      1078         0             0       1078             1             0   \n",
       "1459      1256         0             0       1256             1             0   \n",
       "\n",
       "      FullBath  HalfBath  BedroomAbvGr  KitchenAbvGr KitchenQual  \\\n",
       "0            2         1             3             1          Gd   \n",
       "1            2         0             3             1          TA   \n",
       "2            2         1             3             1          Gd   \n",
       "3            1         0             3             1          Gd   \n",
       "4            2         1             4             1          Gd   \n",
       "...        ...       ...           ...           ...         ...   \n",
       "1455         2         1             3             1          TA   \n",
       "1456         2         0             3             1          TA   \n",
       "1457         2         0             4             1          Gd   \n",
       "1458         1         0             2             1          Gd   \n",
       "1459         1         1             3             1          TA   \n",
       "\n",
       "      TotRmsAbvGrd Functional  Fireplaces FireplaceQu GarageType  GarageYrBlt  \\\n",
       "0                8        Typ           0         NaN     Attchd       2003.0   \n",
       "1                6        Typ           1          TA     Attchd       1976.0   \n",
       "2                6        Typ           1          TA     Attchd       2001.0   \n",
       "3                7        Typ           1          Gd     Detchd       1998.0   \n",
       "4                9        Typ           1          TA     Attchd       2000.0   \n",
       "...            ...        ...         ...         ...        ...          ...   \n",
       "1455             7        Typ           1          TA     Attchd       1999.0   \n",
       "1456             7       Min1           2          TA     Attchd       1978.0   \n",
       "1457             9        Typ           2          Gd     Attchd       1941.0   \n",
       "1458             5        Typ           0         NaN     Attchd       1950.0   \n",
       "1459             6        Typ           0         NaN     Attchd       1965.0   \n",
       "\n",
       "     GarageFinish  GarageCars  GarageArea GarageQual GarageCond PavedDrive  \\\n",
       "0             RFn           2         548         TA         TA          Y   \n",
       "1             RFn           2         460         TA         TA          Y   \n",
       "2             RFn           2         608         TA         TA          Y   \n",
       "3             Unf           3         642         TA         TA          Y   \n",
       "4             RFn           3         836         TA         TA          Y   \n",
       "...           ...         ...         ...        ...        ...        ...   \n",
       "1455          RFn           2         460         TA         TA          Y   \n",
       "1456          Unf           2         500         TA         TA          Y   \n",
       "1457          RFn           1         252         TA         TA          Y   \n",
       "1458          Unf           1         240         TA         TA          Y   \n",
       "1459          Fin           1         276         TA         TA          Y   \n",
       "\n",
       "      WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  \\\n",
       "0              0           61              0          0            0   \n",
       "1            298            0              0          0            0   \n",
       "2              0           42              0          0            0   \n",
       "3              0           35            272          0            0   \n",
       "4            192           84              0          0            0   \n",
       "...          ...          ...            ...        ...          ...   \n",
       "1455           0           40              0          0            0   \n",
       "1456         349            0              0          0            0   \n",
       "1457           0           60              0          0            0   \n",
       "1458         366            0            112          0            0   \n",
       "1459         736           68              0          0            0   \n",
       "\n",
       "      PoolArea PoolQC  Fence MiscFeature  MiscVal  MoSold  YrSold SaleType  \\\n",
       "0            0    NaN    NaN         NaN        0       2    2008       WD   \n",
       "1            0    NaN    NaN         NaN        0       5    2007       WD   \n",
       "2            0    NaN    NaN         NaN        0       9    2008       WD   \n",
       "3            0    NaN    NaN         NaN        0       2    2006       WD   \n",
       "4            0    NaN    NaN         NaN        0      12    2008       WD   \n",
       "...        ...    ...    ...         ...      ...     ...     ...      ...   \n",
       "1455         0    NaN    NaN         NaN        0       8    2007       WD   \n",
       "1456         0    NaN  MnPrv         NaN        0       2    2010       WD   \n",
       "1457         0    NaN  GdPrv        Shed     2500       5    2010       WD   \n",
       "1458         0    NaN    NaN         NaN        0       4    2010       WD   \n",
       "1459         0    NaN    NaN         NaN        0       6    2008       WD   \n",
       "\n",
       "     SaleCondition  SalePrice  \n",
       "0           Normal     208500  \n",
       "1           Normal     181500  \n",
       "2           Normal     223500  \n",
       "3          Abnorml     140000  \n",
       "4           Normal     250000  \n",
       "...            ...        ...  \n",
       "1455        Normal     175000  \n",
       "1456        Normal     210000  \n",
       "1457        Normal     266500  \n",
       "1458        Normal     142125  \n",
       "1459        Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 200\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "prices_df = pd.read_csv('house-prices/train.csv')\n",
    "prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "large-jacob",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1875,
     "status": "ok",
     "timestamp": 1682184396979,
     "user": {
      "displayName": "Sneha Gilada",
      "userId": "11187013067721584331"
     },
     "user_tz": -330
    },
    "id": "large-jacob",
    "outputId": "c7215d06-6774-455d-ae39-60af96202200"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
      "<ipython-input-8-992a95d9f105>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Identify input and target columns\n",
    "input_cols, target_col = prices_df.columns[1:-1], prices_df.columns[-1]\n",
    "inputs_df, targets = prices_df[input_cols].copy(), prices_df[target_col].copy()\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_cols = prices_df[input_cols].select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = prices_df[input_cols].select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Impute and scale numeric columns\n",
    "imputer = SimpleImputer().fit(inputs_df[numeric_cols])\n",
    "inputs_df[numeric_cols] = imputer.transform(inputs_df[numeric_cols])\n",
    "scaler = MinMaxScaler().fit(inputs_df[numeric_cols])\n",
    "inputs_df[numeric_cols] = scaler.transform(inputs_df[numeric_cols])\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(inputs_df[categorical_cols])\n",
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n",
    "inputs_df[encoded_cols] = encoder.transform(inputs_df[categorical_cols])\n",
    "\n",
    "# Create training and validation sets\n",
    "train_inputs, val_inputs, train_targets, val_targets = train_test_split(\n",
    "    inputs_df[numeric_cols + encoded_cols], targets, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-community",
   "metadata": {
    "id": "located-community"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "understood-hostel",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1682184407702,
     "user": {
      "displayName": "Sneha Gilada",
      "userId": "11187013067721584331"
     },
     "user_tz": -330
    },
    "id": "understood-hostel",
    "outputId": "e70d77f0-d71c-49fe-bfcb-18c57cc1d820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Detected Colab notebook...\u001b[0m\n",
      "[jovian] jovian.commit() is no longer required on Google Colab. If you ran this notebook from Jovian, \n",
      "then just save this file in Colab using Ctrl+S/Cmd+S and it will be updated on Jovian. \n",
      "Also, you can also delete this cell, it's no longer necessary.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-pressing",
   "metadata": {
    "id": "unnecessary-pressing"
   },
   "source": [
    "## Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-morning",
   "metadata": {
    "id": "express-morning"
   },
   "source": [
    "> **QUESTION 1**: Train a decision tree regressor using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-aaron",
   "metadata": {
    "id": "limited-aaron"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-possibility",
   "metadata": {
    "id": "champion-possibility"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "tree = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-laptop",
   "metadata": {
    "id": "opposite-laptop"
   },
   "outputs": [],
   "source": [
    "# Fit the model to the training data\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-jewel",
   "metadata": {
    "id": "welsh-jewel"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "geological-fusion",
   "metadata": {
    "id": "geological-fusion"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-eagle",
   "metadata": {
    "id": "progressive-eagle"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-policy",
   "metadata": {
    "id": "contrary-policy"
   },
   "source": [
    "> **QUESTION 2**: Generate predictions on the training and validation sets using the trained decision tree, and compute the RMSE loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-blake",
   "metadata": {
    "id": "helpful-blake"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-november",
   "metadata": {
    "id": "alien-november"
   },
   "outputs": [],
   "source": [
    "tree_train_preds = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-producer",
   "metadata": {
    "id": "received-producer"
   },
   "outputs": [],
   "source": [
    "tree_train_rmse = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-cameroon",
   "metadata": {
    "id": "clinical-cameroon"
   },
   "outputs": [],
   "source": [
    "tree_val_preds = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-indie",
   "metadata": {
    "id": "sapphire-indie"
   },
   "outputs": [],
   "source": [
    "tree_val_rmse = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-program",
   "metadata": {
    "id": "moving-program"
   },
   "outputs": [],
   "source": [
    "print('Train RMSE: {}, Validation RMSE: {}'.format(tree_train_rmse, tree_val_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-first",
   "metadata": {
    "id": "thirty-first"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "handled-dictionary",
   "metadata": {
    "id": "handled-dictionary"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-trader",
   "metadata": {
    "id": "certified-trader"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-wheat",
   "metadata": {
    "id": "russian-wheat"
   },
   "source": [
    "> **QUESTION 3**: Visualize the decision tree (graphically and textually) and display feature importances as a graph. Limit the maximum depth of graphical visualization to 3 levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-hobby",
   "metadata": {
    "id": "moved-hobby"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree, export_text\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-mills",
   "metadata": {
    "id": "foreign-mills"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "# Visualize the tree graphically using plot_tree\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-immunology",
   "metadata": {
    "id": "asian-immunology"
   },
   "outputs": [],
   "source": [
    "# Visualize the tree textually using export_text\n",
    "tree_text = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-knife",
   "metadata": {
    "id": "baking-knife"
   },
   "outputs": [],
   "source": [
    "# Display the first few lines\n",
    "print(tree_text[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-birth",
   "metadata": {
    "id": "typical-birth"
   },
   "outputs": [],
   "source": [
    "# Check feature importance\n",
    "tree_importances = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-reply",
   "metadata": {
    "id": "entertaining-reply"
   },
   "outputs": [],
   "source": [
    "tree_importance_df = pd.DataFrame({\n",
    "    'feature': train_inputs.columns,\n",
    "    'importance': tree_importances\n",
    "}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-ridge",
   "metadata": {
    "id": "limiting-ridge"
   },
   "outputs": [],
   "source": [
    "tree_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-spain",
   "metadata": {
    "id": "amended-spain"
   },
   "outputs": [],
   "source": [
    "plt.title('Decision Tree Feature Importance')\n",
    "sns.barplot(data=tree_importance_df.head(10), x='importance', y='feature');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-alert",
   "metadata": {
    "id": "personal-alert"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "monthly-crazy",
   "metadata": {
    "id": "monthly-crazy"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-material",
   "metadata": {
    "id": "statistical-material"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-option",
   "metadata": {
    "id": "grand-option"
   },
   "source": [
    "## Random Forests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-porcelain",
   "metadata": {
    "id": "imperial-porcelain"
   },
   "source": [
    "> **QUESTION 4**: Train a random forest regressor using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-header",
   "metadata": {
    "id": "given-header"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virtual-mortgage",
   "metadata": {
    "id": "virtual-mortgage"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "rf1 = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-mistress",
   "metadata": {
    "id": "parental-mistress"
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-application",
   "metadata": {
    "id": "metric-application"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "instant-ranking",
   "metadata": {
    "id": "instant-ranking"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-tyler",
   "metadata": {
    "id": "modular-tyler"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-batman",
   "metadata": {
    "id": "proved-batman"
   },
   "source": [
    "> **QUESTION 5**: Make predictions using the random forest regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-driving",
   "metadata": {
    "id": "removable-driving"
   },
   "outputs": [],
   "source": [
    "rf1_train_preds = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-ceremony",
   "metadata": {
    "id": "mature-ceremony"
   },
   "outputs": [],
   "source": [
    "rf1_train_rmse = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-racing",
   "metadata": {
    "id": "unable-racing"
   },
   "outputs": [],
   "source": [
    "rf1_val_preds = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-chaos",
   "metadata": {
    "id": "narrow-chaos"
   },
   "outputs": [],
   "source": [
    "rf1_val_rmse = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-brooks",
   "metadata": {
    "id": "norman-brooks"
   },
   "outputs": [],
   "source": [
    "print('Train RMSE: {}, Validation RMSE: {}'.format(rf1_train_rmse, rf1_val_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-square",
   "metadata": {
    "id": "apparent-square"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "further-camera",
   "metadata": {
    "id": "further-camera"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-exhibit",
   "metadata": {
    "id": "worldwide-exhibit"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-soundtrack",
   "metadata": {
    "id": "confident-soundtrack"
   },
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "Let us now tune the hyperparameters of our model. You can find the hyperparameters for `RandomForestRegressor` here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "<img src=\"https://i.imgur.com/EJCrSZw.png\" width=\"480\">\n",
    "\n",
    "Hyperparameters are use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-makeup",
   "metadata": {
    "id": "narrative-makeup"
   },
   "source": [
    "Let's define a helper function `test_params` which can test the given value of one or more hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-palestine",
   "metadata": {
    "id": "administrative-palestine"
   },
   "outputs": [],
   "source": [
    "def test_params(**params):\n",
    "    model = RandomForestRegressor(random_state=42, n_jobs=-1, **params).fit(train_inputs, train_targets)\n",
    "    train_rmse = mean_squared_error(model.predict(train_inputs), train_targets, squared=False)\n",
    "    val_rmse = mean_squared_error(model.predict(val_inputs), val_targets, squared=False)\n",
    "    return train_rmse, val_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-commander",
   "metadata": {
    "id": "legal-commander"
   },
   "source": [
    "It can be used as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-society",
   "metadata": {
    "id": "banned-society"
   },
   "outputs": [],
   "source": [
    "test_params(n_estimators=20, max_depth=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-bradford",
   "metadata": {
    "id": "outstanding-bradford"
   },
   "outputs": [],
   "source": [
    "test_params(n_estimators=50, max_depth=10, min_samples_leaf=4, max_features=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-diary",
   "metadata": {
    "id": "civilian-diary"
   },
   "source": [
    "Let's also define a helper function to test and plot different values of a single parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-removal",
   "metadata": {
    "id": "australian-removal"
   },
   "outputs": [],
   "source": [
    "def test_param_and_plot(param_name, param_values):\n",
    "    train_errors, val_errors = [], [] \n",
    "    for value in param_values:\n",
    "        params = {param_name: value}\n",
    "        train_rmse, val_rmse = test_params(**params)\n",
    "        train_errors.append(train_rmse)\n",
    "        val_errors.append(val_rmse)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title('Overfitting curve: ' + param_name)\n",
    "    plt.plot(param_values, train_errors, 'b-o')\n",
    "    plt.plot(param_values, val_errors, 'r-o')\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend(['Training', 'Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-webmaster",
   "metadata": {
    "id": "strategic-webmaster"
   },
   "outputs": [],
   "source": [
    "test_param_and_plot('max_depth', [5, 10, 15, 20, 25, 30, 35])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-version",
   "metadata": {
    "id": "reasonable-version"
   },
   "source": [
    "From the above graph, it appears that the best value for `max_depth` is around 20, beyond which the model starts to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-discretion",
   "metadata": {
    "id": "individual-discretion"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "specific-stadium",
   "metadata": {
    "id": "specific-stadium"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-confidentiality",
   "metadata": {
    "id": "choice-confidentiality"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-configuration",
   "metadata": {
    "id": "bottom-configuration"
   },
   "source": [
    "> **QUESTION 6**: Use the `test_params` and `test_param_and_plot` functions to experiment with different values of the  hyperparmeters like `n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`, `min_weight_fraction_leaf`, `max_features`, `max_leaf_nodes`, `min_impurity_decrease`, `min_impurity_split` etc. You can learn more about the hyperparameters here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guided-costs",
   "metadata": {
    "id": "guided-costs"
   },
   "outputs": [],
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-timer",
   "metadata": {
    "id": "extraordinary-timer"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-collins",
   "metadata": {
    "id": "legislative-collins"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-engine",
   "metadata": {
    "id": "supposed-engine"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "heard-creator",
   "metadata": {
    "id": "heard-creator"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-apollo",
   "metadata": {
    "id": "proper-apollo"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-charger",
   "metadata": {
    "id": "swiss-charger"
   },
   "source": [
    "## Training the Best Model\n",
    "\n",
    "> **QUESTION 7**: Train a random forest regressor model with your best hyperparameters to minimize the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-seven",
   "metadata": {
    "id": "visible-seven"
   },
   "outputs": [],
   "source": [
    "# Create the model with custom hyperparameters\n",
    "rf2 = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-nickname",
   "metadata": {
    "id": "sonic-nickname"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-briefs",
   "metadata": {
    "id": "collectible-briefs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "prompt-lawrence",
   "metadata": {
    "id": "prompt-lawrence"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-essex",
   "metadata": {
    "id": "oriental-essex"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-chamber",
   "metadata": {
    "id": "afraid-chamber"
   },
   "source": [
    "> **QUESTION 8**: Make predictions and evaluate your final model. If you're unhappy with the results, modify the hyperparameters above and try again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-constraint",
   "metadata": {
    "id": "latest-constraint"
   },
   "outputs": [],
   "source": [
    "rf2_train_preds = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-musician",
   "metadata": {
    "id": "expected-musician"
   },
   "outputs": [],
   "source": [
    "rf2_train_rmse = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-brand",
   "metadata": {
    "id": "equivalent-brand"
   },
   "outputs": [],
   "source": [
    "rf2_val_preds = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-dealer",
   "metadata": {
    "id": "sacred-dealer"
   },
   "outputs": [],
   "source": [
    "rf2_val_rmse = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-musician",
   "metadata": {
    "id": "relevant-musician"
   },
   "outputs": [],
   "source": [
    "print('Train RMSE: {}, Validation RMSE: {}'.format(rf2_train_rmse, rf2_val_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-player",
   "metadata": {
    "id": "average-player"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "danish-filename",
   "metadata": {
    "id": "danish-filename"
   },
   "source": [
    "Let's also view and plot the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-circle",
   "metadata": {
    "id": "measured-circle"
   },
   "outputs": [],
   "source": [
    "rf2_importance_df = pd.DataFrame({\n",
    "    'feature': train_inputs.columns,\n",
    "    'importance': rf2.feature_importances_\n",
    "}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-thickness",
   "metadata": {
    "id": "insured-thickness"
   },
   "outputs": [],
   "source": [
    "rf2_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-explanation",
   "metadata": {
    "id": "standard-explanation"
   },
   "outputs": [],
   "source": [
    "sns.barplot(data=rf2_importance_df, x='importance', y='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-xerox",
   "metadata": {
    "id": "junior-xerox"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "soviet-springer",
   "metadata": {
    "id": "soviet-springer"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-majority",
   "metadata": {
    "id": "tested-majority"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba58fc60",
   "metadata": {
    "id": "ba58fc60"
   },
   "source": [
    "## LeetCode Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c0969",
   "metadata": {
    "id": "1d5c0969"
   },
   "source": [
    "### [Problem 46](https://leetcode.com/problems/permutations/) - Permutations\n",
    "\n",
    "Given an array `nums` of distinct integers, return *all the possible permutations*. You can return the answer in **any order**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8d8b7e",
   "metadata": {
    "id": "6c8d8b7e"
   },
   "source": [
    "Example 1:\n",
    "```\n",
    "Input: nums = [1,2,3]\n",
    "Output: [[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]\n",
    "```\n",
    "Example 2:\n",
    "```\n",
    "Input: nums = [0,1]\n",
    "Output: [[0,1],[1,0]]\n",
    "```\n",
    "Example 3:\n",
    "```\n",
    "Input: nums = [1]\n",
    "Output: [[1]]\n",
    "```\n",
    "\n",
    "Constraints:\n",
    "```\n",
    "1 <= nums.length <= 6\n",
    "-10 <= nums[i] <= 10\n",
    "All the integers of nums are unique.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff318c9c",
   "metadata": {
    "id": "ff318c9c"
   },
   "outputs": [],
   "source": [
    "def permute(nums):\n",
    "    ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c2b592",
   "metadata": {
    "id": "74c2b592"
   },
   "outputs": [],
   "source": [
    "# This should return \"True\"\n",
    "permute([1,2,3]) == [[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfbf5ce",
   "metadata": {
    "id": "5bfbf5ce"
   },
   "outputs": [],
   "source": [
    "# This should return \"True\"\n",
    "permute([0,1]) == [[0,1],[1,0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d206a9",
   "metadata": {
    "id": "88d206a9"
   },
   "source": [
    "### [Problem 43](https://leetcode.com/problems/multiply-strings/) - Multiply Strings\n",
    "\n",
    "Given two non-negative integers `num1` and `num2` represented as strings, return the product of `num1` and `num2`, also represented as a string.\n",
    "\n",
    "**Note:** You must not use any built-in BigInteger library or convert the inputs to integer directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1699942",
   "metadata": {
    "id": "c1699942"
   },
   "source": [
    "Example 1:\n",
    "```\n",
    "Input: num1 = \"2\", num2 = \"3\"\n",
    "Output: \"6\"\n",
    "```\n",
    "Example 2:\n",
    "```\n",
    "Input: num1 = \"123\", num2 = \"456\"\n",
    "Output: \"56088\"\n",
    "```\n",
    "\n",
    "Constraints:\n",
    "```\n",
    "1 <= num1.length, num2.length <= 200\n",
    "num1 and num2 consist of digits only.\n",
    "Both num1 and num2 do not contain any leading zero, except the number 0 itself.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04af9cd",
   "metadata": {
    "id": "d04af9cd"
   },
   "outputs": [],
   "source": [
    "def multiply(num1, num2):\n",
    "    ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec1dc0",
   "metadata": {
    "id": "0bec1dc0"
   },
   "outputs": [],
   "source": [
    "# This should return \"True\"\n",
    "multiply(\"2\",\"3\") == \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182d356",
   "metadata": {
    "id": "d182d356"
   },
   "outputs": [],
   "source": [
    "# This should return \"True\"\n",
    "multiply(\"123\",\"456\") == \"56088\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-brush",
   "metadata": {
    "id": "sharp-brush"
   },
   "source": [
    "## Make a Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-cornell",
   "metadata": {
    "id": "matched-cornell"
   },
   "source": [
    "You can submit your Jovian notebook link on the assignment `submit` tab page\n",
    "\n",
    "Make sure to review the evaluation criteria carefully. You can make any number of submissions, and only your final submission will be evalauted.\n",
    "\n",
    "NOTE: **The rest of this assignment is optional.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-scotland",
   "metadata": {
    "id": "further-scotland"
   },
   "source": [
    "## Making Predictions on the Test Set\n",
    "\n",
    "Let's make predictions on the test set provided with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-roots",
   "metadata": {
    "id": "specialized-roots"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('house-prices/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-marshall",
   "metadata": {
    "id": "related-marshall"
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-government",
   "metadata": {
    "id": "hourly-government"
   },
   "source": [
    "First, we need to reapply all the preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-chick",
   "metadata": {
    "id": "sunset-chick"
   },
   "outputs": [],
   "source": [
    "test_df[numeric_cols] = imputer.transform(test_df[numeric_cols])\n",
    "test_df[numeric_cols] = scaler.transform(test_df[numeric_cols])\n",
    "test_df[encoded_cols] = encoder.transform(test_df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-contract",
   "metadata": {
    "id": "thirty-contract"
   },
   "outputs": [],
   "source": [
    "test_inputs = test_df[numeric_cols + encoded_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-constitutional",
   "metadata": {
    "id": "secret-constitutional"
   },
   "source": [
    "We can now make predictions using our final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-edinburgh",
   "metadata": {
    "id": "extreme-edinburgh"
   },
   "outputs": [],
   "source": [
    "test_preds = rf2.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-charger",
   "metadata": {
    "id": "solid-charger"
   },
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv('house-prices/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-adobe",
   "metadata": {
    "id": "fifth-adobe"
   },
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-seven",
   "metadata": {
    "id": "capital-seven"
   },
   "source": [
    "Let's replace the values of the `SalePrice` column with our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-learning",
   "metadata": {
    "id": "personal-learning"
   },
   "outputs": [],
   "source": [
    "submission_df['SalePrice'] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-monitoring",
   "metadata": {
    "id": "informed-monitoring"
   },
   "source": [
    "Let's save it as a CSV file and download it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-missile",
   "metadata": {
    "id": "polish-missile"
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-national",
   "metadata": {
    "id": "acting-national"
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('submission.csv') # Doesn't work on Colab, use the file browser instead to download the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-knowing",
   "metadata": {
    "id": "national-knowing"
   },
   "source": [
    "We can now submit this file to the competition: https://www.kaggle.com/c/house-prices-advanced-regression-techniques/submissions\n",
    "\n",
    "![](https://i.imgur.com/6h2vXRq.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-intention",
   "metadata": {
    "id": "twelve-intention"
   },
   "source": [
    "> **(OPTIONAL) QUESTION**: Submit your predictions to the competition. Experiment with different models, feature engineering strategies and hyperparameters and try to reach the top 10% on the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-beverage",
   "metadata": {
    "id": "super-beverage"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-establishment",
   "metadata": {
    "id": "accredited-establishment"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-instruction",
   "metadata": {
    "id": "pediatric-instruction"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-smooth",
   "metadata": {
    "id": "seven-smooth"
   },
   "outputs": [],
   "source": [
    "jovian.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-belize",
   "metadata": {
    "id": "suffering-belize"
   },
   "source": [
    "### Making Predictions on Single Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-hindu",
   "metadata": {
    "id": "extended-hindu"
   },
   "outputs": [],
   "source": [
    "def predict_input(model, single_input):\n",
    "    input_df = pd.DataFrame([single_input])\n",
    "    input_df[numeric_cols] = imputer.transform(input_df[numeric_cols])\n",
    "    input_df[numeric_cols] = scaler.transform(input_df[numeric_cols])\n",
    "    input_df[encoded_cols] = encoder.transform(input_df[categorical_cols].values)\n",
    "    return model.predict(input_df[numeric_cols + encoded_cols])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-concentration",
   "metadata": {
    "id": "portuguese-concentration"
   },
   "outputs": [],
   "source": [
    "sample_input = { 'MSSubClass': 20, 'MSZoning': 'RL', 'LotFrontage': 77.0, 'LotArea': 9320,\n",
    " 'Street': 'Pave', 'Alley': None, 'LotShape': 'IR1', 'LandContour': 'Lvl', 'Utilities': 'AllPub',\n",
    " 'LotConfig': 'Inside', 'LandSlope': 'Gtl', 'Neighborhood': 'NAmes', 'Condition1': 'Norm', 'Condition2': 'Norm',\n",
    " 'BldgType': '1Fam', 'HouseStyle': '1Story', 'OverallQual': 4, 'OverallCond': 5, 'YearBuilt': 1959,\n",
    " 'YearRemodAdd': 1959, 'RoofStyle': 'Gable', 'RoofMatl': 'CompShg', 'Exterior1st': 'Plywood',\n",
    " 'Exterior2nd': 'Plywood', 'MasVnrType': 'None','MasVnrArea': 0.0,'ExterQual': 'TA','ExterCond': 'TA',\n",
    " 'Foundation': 'CBlock','BsmtQual': 'TA','BsmtCond': 'TA','BsmtExposure': 'No','BsmtFinType1': 'ALQ',\n",
    " 'BsmtFinSF1': 569,'BsmtFinType2': 'Unf','BsmtFinSF2': 0,'BsmtUnfSF': 381,\n",
    " 'TotalBsmtSF': 950,'Heating': 'GasA','HeatingQC': 'Fa','CentralAir': 'Y','Electrical': 'SBrkr', '1stFlrSF': 1225,\n",
    " '2ndFlrSF': 0, 'LowQualFinSF': 0, 'GrLivArea': 1225, 'BsmtFullBath': 1, 'BsmtHalfBath': 0, 'FullBath': 1,\n",
    " 'HalfBath': 1, 'BedroomAbvGr': 3, 'KitchenAbvGr': 1,'KitchenQual': 'TA','TotRmsAbvGrd': 6,'Functional': 'Typ',\n",
    " 'Fireplaces': 0,'FireplaceQu': np.nan,'GarageType': np.nan,'GarageYrBlt': np.nan,'GarageFinish': np.nan,'GarageCars': 0,\n",
    " 'GarageArea': 0,'GarageQual': np.nan,'GarageCond': np.nan,'PavedDrive': 'Y', 'WoodDeckSF': 352, 'OpenPorchSF': 0,\n",
    " 'EnclosedPorch': 0,'3SsnPorch': 0, 'ScreenPorch': 0, 'PoolArea': 0, 'PoolQC': np.nan, 'Fence': np.nan, 'MiscFeature': 'Shed',\n",
    " 'MiscVal': 400, 'MoSold': 1, 'YrSold': 2010, 'SaleType': 'WD', 'SaleCondition': 'Normal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-duplicate",
   "metadata": {
    "id": "reverse-duplicate"
   },
   "outputs": [],
   "source": [
    "predicted_price = predict_input(rf2, sample_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-elizabeth",
   "metadata": {
    "id": "protective-elizabeth"
   },
   "outputs": [],
   "source": [
    "print('The predicted sale price of the house is ${}'.format(predicted_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-pursuit",
   "metadata": {
    "id": "unlimited-pursuit"
   },
   "source": [
    "> **EXERCISE**: Change the sample input above and make predictions. Try different examples and try to figure out which columns have a big impact on the sale price. Hint: Look at the feature importance to decide which columns to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-percentage",
   "metadata": {
    "id": "unable-percentage"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-decade",
   "metadata": {
    "id": "legislative-decade"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eight-source",
   "metadata": {
    "id": "eight-source"
   },
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-insight",
   "metadata": {
    "id": "boring-insight"
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-distribution",
   "metadata": {
    "id": "practical-distribution"
   },
   "outputs": [],
   "source": [
    "house_prices_rf = {\n",
    "    'model': rf2,\n",
    "    'imputer': imputer,\n",
    "    'scaler': scaler,\n",
    "    'encoder': encoder,\n",
    "    'input_cols': input_cols,\n",
    "    'target_col': target_col,\n",
    "    'numeric_cols': numeric_cols,\n",
    "    'categorical_cols': categorical_cols,\n",
    "    'encoded_cols': encoded_cols\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-spoke",
   "metadata": {
    "id": "animated-spoke"
   },
   "outputs": [],
   "source": [
    "joblib.dump(house_prices_rf, 'house_prices_rf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-culture",
   "metadata": {
    "id": "normal-culture"
   },
   "source": [
    "Let's save our work before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-primary",
   "metadata": {
    "id": "fallen-primary"
   },
   "outputs": [],
   "source": [
    "jovian.commit(outputs=['house_prices_rf.joblib'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-insight",
   "metadata": {
    "id": "biblical-insight"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "loved-clause",
   "metadata": {
    "id": "loved-clause"
   },
   "source": [
    "### Predicting the Logarithm of Sale Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-introduction",
   "metadata": {
    "id": "talented-introduction"
   },
   "source": [
    "> **(OPTIONAL) QUESTION**: In the [original Kaggle competition](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview/evaluation), the model is evaluated by computing the Root Mean Squared Error on the logarithm of the sale price. Try training a random forest to predict the logarithm of the sale price, instead of the actual sales price and see if the results you obtain are better than the models trained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-lobby",
   "metadata": {
    "id": "driven-lobby"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-island",
   "metadata": {
    "id": "entitled-island"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}